{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518ac500-1d45-47c2-9ee4-64ca4b810244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "path = '/home/akazemi3/Desktop/MB_Lab_Project/'\n",
    "sys.path.append(path)\n",
    "from analysis.neural_data_regression.tools.regression import *\n",
    "\n",
    "from tools.processing import *\n",
    "from tools.loading import *\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from analysis.neural_data_regression.tools.utils import get_activations_iden, get_scores_iden\n",
    "BEST_ALPHA_PATH = '/data/atlas/regression_alphas'    \n",
    "ROOT_PATH = '/data/atlas/model_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da066bb2-2170-48a8-9c49-c8c6c619f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_activations_iden(dataset, model_info):\n",
    "    \n",
    "#         model_name = model_info['iden'] \n",
    "        \n",
    "#         if model_info['max_pool']:\n",
    "#             model_name = model_name + '_mp' \n",
    "\n",
    "#         activations_identifier = model_name + '_' + f'{model_info[\"num_layers\"]}_layers' + '_' + f'{model_info[\"num_features\"]}_features' \n",
    "\n",
    "#         if model_info['pca']:\n",
    "#             activations_identifier = activations_identifier + '_' + f'{model_info[\"pca_type\"]}' + '_' + f'{model_info[\"max_pca_components\"]}' + '_'  + f'{model_info[\"pca_dataset\"]}' + '_' + 'pcs' \n",
    "\n",
    "#         if mode == 'cv' and dataset == 'naturalscenes':\n",
    "#             return activations_identifier + '_' + dataset + '_' + 'shared'\n",
    "  \n",
    "#         else:\n",
    "#             return activations_identifier + '_' + dataset \n",
    "\n",
    "\n",
    "\n",
    "# def get_scores_iden(model_info, activations_identifier, region, mode, alpha):\n",
    "    \n",
    "#     if model_info['pca']:\n",
    "#         activations_identifier = activations_identifier.split(f'_{dataset}')[0] \n",
    "#         scores_identifier = activations_identifier + '_' + f'{model_info[\"num_pca_components\"]}' + '_' + 'subset' + '_' + dataset + '_' + region + '_' + mode + '_' + f'ridge(alpha={alpha})'\n",
    "#     else:\n",
    "#         scores_identifier = activations_identifier + '_' + region + '_' + mode + '_' + f'ridge(alpha={alpha})' \n",
    "#     return scores_identifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33507f35-cf51-4df2-9acc-c03391998204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_alpha(data_dict, dataset, mode, region):\n",
    "    \n",
    "            \n",
    "    root_path = '/data/atlas/model_scores'\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    index = 0\n",
    "    for model_name, model_info in data_dict.items():\n",
    "                \n",
    "        for alpha in model_info['alphas']:\n",
    "\n",
    "            regression = f'Ridge(alpha={alpha})' \n",
    "                \n",
    "\n",
    "            activations_iden = get_activations_iden(model_info, dataset, mode)\n",
    "            scores_iden = get_scores_iden(model_info, activations_iden, region, dataset, mode, alpha)\n",
    "            \n",
    "            data = xr.open_dataset(os.path.join(root_path,activations_iden,scores_iden))\n",
    "            r_values = data.where(data.region == region,drop=True).r_value.values\n",
    "            mean_r = np.mean(r_values)\n",
    "            df_tmp =  pd.DataFrame({'mean_score':mean_r,\n",
    "                                    'alpha':alpha,\n",
    "                                    'model':model_name},index=[index])\n",
    "            df = pd.concat([df,df_tmp])\n",
    "            index += 1\n",
    "\n",
    "    \n",
    "    df = df.groupby(['model','alpha']).mean().reset_index()\n",
    "    max_idx = df.groupby(['model']).agg({'mean_score':('idxmax')}).reset_index()['mean_score'].tolist()\n",
    "    df_max_alphas = df.loc[max_idx].reset_index(drop=True)\n",
    "\n",
    "    return df_max_alphas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4b2046-22c6-4d00-831f-0e337474ea1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Untrained alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a793aa6-06eb-478b-bd4e-160305e7ca4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68416332-136f-4a98-9c88-11f5650f40b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "                     model  alpha  mean_score\n",
      "0  alexnet u wide 1000 pcs    100    0.212800\n",
      "1   alexnet u wide 256 pcs    100    0.210379\n",
      "2  alexnet u wide 5000 pcs    100    0.213531\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_u_wide_pca'\n",
    "MAX_POOL = False    \n",
    "\n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "\n",
    "    \n",
    "        'alexnet u wide 256 pcs':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetUPCA(n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':10000,\n",
    "                'pca_dataset':'nsd',\n",
    "                'n_dims':256,\n",
    "                'max_dims':5000,\n",
    "                'dim_reduction_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]}, \n",
    "\n",
    "        'alexnet u wide 1000 pcs':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetUPCA(n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':10000,\n",
    "                'pca_dataset':'nsd',\n",
    "                'n_dims':1000,\n",
    "                'max_dims':5000,\n",
    "                'dim_reduction_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},     \n",
    "        \n",
    "         \n",
    "        'alexnet u wide 5000 pcs':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetUPCA(n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':10000,\n",
    "                'pca_dataset':'nsd',\n",
    "                'n_dims':5000,\n",
    "                'max_dims':5000,\n",
    "                'dim_reduction_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},\n",
    "}\n",
    "\n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3df66-a3f1-4c8c-a34e-7fb2b69aba20",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### random projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "853f169a-8c91-4871-899d-508c70fc86f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "                     model  alpha  mean_score\n",
      "0  alexnet u wide 1000 rps     10    0.190630\n",
      "1   alexnet u wide 256 rps     10    0.168940\n",
      "2  alexnet u wide 5000 rps     10    0.206167\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_u_wide_rp'\n",
    "\n",
    "\n",
    "MAX_POOL = False                \n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        \n",
    "        'alexnet u wide 256 rps':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetU(filters_5 = 10000, num_projections=256, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':10000,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'n_dims':256,\n",
    "                'alphas': [10**i for i in range(1,4)]},  \n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "       'alexnet u wide 1000 rps':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetU(filters_5 = 10000, num_projections=1000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':10000,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'n_dims':1000,\n",
    "                'alphas': [10**i for i in range(1,4)]},  \n",
    "        \n",
    "        \n",
    "    \n",
    "           'alexnet u wide 5000 rps':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetU(filters_5 = 10000, num_projections=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':10000,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'n_dims':5000,\n",
    "                'alphas': [10**i for i in range(1,4)]},       \n",
    "    }\n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa83ecd-c9ef-48cd-82e1-e957d29a9ae0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7e585fb-1b77-454d-885e-d457848b67f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "                          model  alpha  mean_score\n",
      "0     alexnet u wide 10 filters     10    0.084169\n",
      "1    alexnet u wide 100 filters     10    0.118336\n",
      "2   alexnet u wide 1000 filters     10    0.161645\n",
      "3  alexnet u wide 10000 filters     10    0.188697\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_u_wide_mp'\n",
    "\n",
    "\n",
    "MAX_POOL = True\n",
    "\n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        \n",
    "       'alexnet u wide 10 filters':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetUWide(filters_5 = 10, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':10,\n",
    "                'dim_reduction_type':None,\n",
    "                 'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},  \n",
    "        \n",
    "    \n",
    "         \n",
    "       'alexnet u wide 100 filters':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetUWide(filters_5 = 100, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':100,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},     \n",
    "    \n",
    "    \n",
    "       'alexnet u wide 1000 filters':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetUWide(filters_5 = 1000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':1000,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},  \n",
    "\n",
    "    \n",
    "    \n",
    "       'alexnet u wide 10000 filters':{\n",
    "                'iden':'alexnet_u_wide',\n",
    "                #'model':AlexnetUWide(filters_5 = 10000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':10000,\n",
    "                'dim_reduction_type':None,\n",
    "                 'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},   \n",
    "            }\n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55f3b8-0fa4-429a-8ac1-c06655319d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce0054-ec40-4ba1-a00e-55af61cf30c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b30b74f-fa53-4e82-b8d6-bd2cb14459b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Engineered Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753817b4-8008-4bd4-865b-f3f3160df742",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "146b5fcc-b31f-443c-93e2-564c56a44609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "                                model  alpha  mean_score\n",
      "0     model abs 3x3 bp 224 10 filters    100    0.080929\n",
      "1    model abs 3x3 bp 224 100 filters    100    0.133710\n",
      "2   model abs 3x3 bp 224 1000 filters    100    0.176358\n",
      "3  model abs 3x3 bp 224 10000 filters    100    0.201933\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'model_abs_3x3_bp_224_mp'\n",
    "\n",
    "\n",
    "MAX_POOL = True\n",
    "\n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        'model abs 3x3 bp 224 10 filters':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBP(filters_3 = 10, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]},  \n",
    "\n",
    "    \n",
    "    \n",
    "        'model abs 3x3 bp 224 100 filters':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBP(filters_3 = 100, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':100,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]},  \n",
    "        \n",
    "    \n",
    "         \n",
    "        'model abs 3x3 bp 224 1000 filters':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBP(filters_3 = 1000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':1000,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]},    \n",
    "\n",
    "\n",
    "        'model abs 3x3 bp 224 10000 filters':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBP(filters_3 = 10000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]},  \n",
    "    }\n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c399604b-d0d6-4545-832a-bbeb277f4038",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7945c47d-e998-4843-aa03-01fa26a1cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "                           model  alpha  mean_score\n",
      "0  model abs 3x3 bp 224 1000 pcs    100    0.215848\n",
      "1   model abs 3x3 bp 224 256 pcs    100    0.212651\n",
      "2  model abs 3x3 bp 224 5000 pcs    100    0.216922\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'model_abs_3x3_bp_224_pca'\n",
    "\n",
    "\n",
    "MAX_POOL = False                \n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "\n",
    "        'model abs 3x3 bp 224 256 pcs':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBPPCA(filters_3 = 10000, n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'pca':True,\n",
    "                'pca_dataset':'nsd',\n",
    "                'num_pca_components':256,\n",
    "                'max_pca_components':5000,\n",
    "                'pca_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]}, \n",
    "\n",
    "        'model abs 3x3 bp 224 1000 pcs':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBPPCA(filters_3 = 10000, n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'pca':True,\n",
    "                'pca_dataset':'nsd',\n",
    "                'num_pca_components':1000,\n",
    "                'max_pca_components':5000,\n",
    "                'pca_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,5)]},   \n",
    "        \n",
    "         \n",
    "        'model abs 3x3 bp 224 5000 pcs':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBPPCA(filters_3 = 10000, n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'pca':True,\n",
    "                'pca_dataset':'nsd',\n",
    "                'num_pca_components':5000,\n",
    "                'max_pca_components':5000,\n",
    "                'pca_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]},     \n",
    "    }\n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d31069c-66fd-47ee-a8cf-4991230c0efe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b964e3b-aa7d-4443-bbe7-30601f0e9f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "                           model  alpha  mean_score\n",
      "0  model abs 3x3 bp 224 1000 rps    100    0.192254\n",
      "1   model abs 3x3 bp 224 256 rps    100    0.168394\n",
      "2  model abs 3x3 bp 224 5000 rps    100    0.208484\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'model_abs_3x3_bp_224_rp'\n",
    "\n",
    "MAX_POOL = False              \n",
    "\n",
    "\n",
    "for region in REGIONS:\n",
    "    data_dict = {        \n",
    "        'model abs 3x3 bp 224 256 rps':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBP(filters_3 = 10000, num_projections=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'n_dims':256,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'max_dims':256,\n",
    "                'alphas': [10**i for i in range(2,5)]},  \n",
    "\n",
    "        'model abs 3x3 bp 224 1000 rps':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBP(filters_3 = 10000, num_projections=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'n_dims':1000,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'max_dims':1000,\n",
    "                'alphas': [10**i for i in range(2,5)]},  \n",
    "        \n",
    "         \n",
    "        'model abs 3x3 bp 224 5000 rps':{\n",
    "                'iden':'model_abs_3x3_bp_224',\n",
    "                #'model':EngModel3LAbsBP(filters_3 = 10000, num_projections=5000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'n_dims':5000,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'max_dims':5000,\n",
    "                'alphas': [10**i for i in range(2,5)]},     \n",
    "   }\n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad191729-0e38-4f9d-ba52-73418511b1b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9bcc0-217b-44e5-a07e-affdba5f898c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "133ddf3f-2fa4-4f1f-aee4-a0a5ecac3ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "     model   alpha  mean_score\n",
      "0  alexnet  100000    0.208461\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_mp'\n",
    "\n",
    "\n",
    "MAX_POOL = True                \n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        \n",
    "       'alexnet':{\n",
    "                'iden':'alexnet',\n",
    "                #'model':Alexnet(global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(3,7)]},            \n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f3b3416-d573-4cb4-9b2d-7fc507072e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n",
      "             model  alpha  mean_score\n",
      "0        alexnet u     10    0.228549\n",
      "1  alexnet u conv1   1000    0.157694\n",
      "2  alexnet u conv2    100    0.219965\n",
      "3  alexnet u conv3     10    0.252143\n",
      "4  alexnet u conv4     10    0.256974\n",
      "V2\n",
      "             model  alpha  mean_score\n",
      "0        alexnet u     10    0.187537\n",
      "1  alexnet u conv1   1000    0.125786\n",
      "2  alexnet u conv2    100    0.181930\n",
      "3  alexnet u conv3    100    0.208063\n",
      "4  alexnet u conv4     10    0.215074\n",
      "V3\n",
      "             model  alpha  mean_score\n",
      "0        alexnet u     10    0.154471\n",
      "1  alexnet u conv1   1000    0.107891\n",
      "2  alexnet u conv2    100    0.150582\n",
      "3  alexnet u conv3    100    0.172681\n",
      "4  alexnet u conv4     10    0.177915\n",
      "V4\n",
      "             model  alpha  mean_score\n",
      "0        alexnet u     10    0.136087\n",
      "1  alexnet u conv1   1000    0.111485\n",
      "2  alexnet u conv2    100    0.140064\n",
      "3  alexnet u conv3    100    0.154744\n",
      "4  alexnet u conv4     10    0.156733\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V1','V2','V3','V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_u_mp'\n",
    "\n",
    "\n",
    "MAX_POOL = True                \n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        \n",
    "    \n",
    "       'alexnet u conv1':{\n",
    "                'iden':'alexnet_u_conv1',\n",
    "                #'model':AlexnetU(features_layer =2, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':1,\n",
    "                'num_features':64,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,6)]},   \n",
    "       \n",
    "        'alexnet u conv2':{\n",
    "                'iden':'alexnet_u_conv2',\n",
    "                #'model':AlexnetU(features_layer =5, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':2,\n",
    "                'num_features':192,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},   \n",
    "       \n",
    "        'alexnet u conv3':{\n",
    "                'iden':'alexnet_u_conv3',\n",
    "                #'model':AlexnetU(features_layer =7, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':3,\n",
    "                'num_features':384,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},   \n",
    "       \n",
    "        'alexnet u conv4':{\n",
    "                'iden':'alexnet_u_conv4',\n",
    "                #'model':AlexnetU(features_layer =9, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':4,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},       \n",
    "        \n",
    "        'alexnet u':{\n",
    "                'iden':'alexnet_u',\n",
    "                #'model':AlexnetU(global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]}, \n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0afa2a2a-beab-472f-8ab3-033ba73aafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n",
      "           model    alpha  mean_score\n",
      "0        alexnet   100000    0.239833\n",
      "1  alexnet conv1    10000    0.168182\n",
      "2  alexnet conv2   100000    0.246923\n",
      "3  alexnet conv3  1000000    0.265467\n",
      "4  alexnet conv4   100000    0.248129\n",
      "V2\n",
      "           model    alpha  mean_score\n",
      "0        alexnet   100000    0.215266\n",
      "1  alexnet conv1    10000    0.135811\n",
      "2  alexnet conv2   100000    0.211548\n",
      "3  alexnet conv3  1000000    0.235125\n",
      "4  alexnet conv4   100000    0.222569\n",
      "V3\n",
      "           model    alpha  mean_score\n",
      "0        alexnet   100000    0.197312\n",
      "1  alexnet conv1    10000    0.118892\n",
      "2  alexnet conv2   100000    0.181828\n",
      "3  alexnet conv3  1000000    0.208914\n",
      "4  alexnet conv4   100000    0.201077\n",
      "V4\n",
      "           model    alpha  mean_score\n",
      "0        alexnet   100000    0.208461\n",
      "1  alexnet conv1   100000    0.126201\n",
      "2  alexnet conv2   100000    0.178070\n",
      "3  alexnet conv3  1000000    0.207005\n",
      "4  alexnet conv4   100000    0.205107\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V1','V2','V3','V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_mp'\n",
    "\n",
    "\n",
    "MAX_POOL = True                \n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        \n",
    "    \n",
    "       'alexnet conv1':{\n",
    "                'iden':'alexnet_conv1',\n",
    "                #'model':Alexnet(features_layer =2, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':1,\n",
    "                'num_features':64,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(3,7)]},            \n",
    "    \n",
    "       'alexnet conv2':{\n",
    "                'iden':'alexnet_conv2',\n",
    "                #'model':Alexnet(features_layer =5, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':2,\n",
    "                'num_features':192,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(3,7)]},      \n",
    "    \n",
    "       'alexnet conv3':{\n",
    "                'iden':'alexnet_conv3',\n",
    "                #'model':Alexnet(features_layer =7, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':3,\n",
    "                'num_features':384,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(3,9)]},    \n",
    "    \n",
    "       'alexnet conv4':{\n",
    "                'iden':'alexnet_conv4',\n",
    "               #'model':Alexnet(features_layer =9, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':4,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(3,7)]},     \n",
    "        \n",
    "       'alexnet':{\n",
    "                'iden':'alexnet',\n",
    "               #'model':Alexnet(global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(3,7)]},      \n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd1eb3-1891-4b52-9053-995c018cdf85",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff5b412-95c0-4cab-9af9-e1a72b6757ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "             model  alpha  mean_score\n",
      "0   alexnet 10 pcs  10000    0.193673\n",
      "1  alexnet 100 pcs  10000    0.202346\n",
      "2  alexnet 256 pcs  10000    0.193292\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_mp_pca'\n",
    "\n",
    "\n",
    "MAX_POOL = True                \n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "\n",
    "    'alexnet 10 pcs':{\n",
    "                'iden':'alexnet',\n",
    "                #'model':AlexnetPCA(n_components=256, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['pca5'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'pca':True,\n",
    "                'pca_dataset':'nsd',\n",
    "                'num_pca_components':10,\n",
    "                'max_pca_components':256,\n",
    "                'pca_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]}, \n",
    "        \n",
    "        'alexnet 100 pcs':{\n",
    "                'iden':'alexnet',\n",
    "                #'model':AlexnetPCA(n_components=256, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['pca5'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'pca':True,\n",
    "                'pca_dataset':'nsd',\n",
    "                'num_pca_components':100,\n",
    "                'max_pca_components':256,\n",
    "                'pca_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]}, \n",
    "        \n",
    "        'alexnet 256 pcs':{\n",
    "                'iden':'alexnet',\n",
    "                #'model':AlexnetPCA(n_components=256, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['pca5'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'pca':True,\n",
    "                'pca_dataset':'nsd',\n",
    "                'num_pca_components':256,\n",
    "                'max_pca_components':256,\n",
    "                'pca_type':'pca',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(2,5)]}, \n",
    "        \n",
    "        \n",
    "#         'alexnet 256 pcs':{\n",
    "#                 'iden':'alexnet',\n",
    "#                 #'model':AlexnetPCA(n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['pca5'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':256,\n",
    "#                 'pca':True,\n",
    "#                 'pca_dataset':'nsd',\n",
    "#                 'num_pca_components':256,\n",
    "#                 'max_pca_components':5000,\n",
    "#                 'pca_type':'pca',\n",
    "#                 'max_pool':MAX_POOL,\n",
    "#                 'alphas': [10**i for i in range(2,5)]},\n",
    "        \n",
    "                 # 'alexnet 1000 pcs':{\n",
    "#                 'iden':'alexnet',\n",
    "#                 #'model':AlexnetPCA(n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['pca5'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':256,\n",
    "#                 'pca':True,\n",
    "#                 'pca_dataset':'nsd',\n",
    "#                 'num_pca_components':1000,\n",
    "#                 'max_pca_components':5000,\n",
    "#                 'pca_type':'pca',\n",
    "#                 'max_pool':MAX_POOL,\n",
    "#                 'alphas': [10**i for i in range(2,5)]}, \n",
    "    \n",
    "#         'alexnet 5000 pcs':{\n",
    "#                 'iden':'alexnet',\n",
    "#                 #'model':AlexnetPCA(n_components=5000, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['pca5'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':256,\n",
    "#                 'pca':True,\n",
    "#                 'pca_dataset':'nsd',\n",
    "#                 'num_pca_components':5000,\n",
    "#                 'max_pca_components':5000,\n",
    "#                 'pca_type':'pca',\n",
    "#                 'max_pool':MAX_POOL,\n",
    "#                 'alphas': [10**i for i in range(2,5)]}, \n",
    "\n",
    "        }\n",
    "\n",
    "df_best_alpha = get_best_alpha(data_dict)\n",
    "print(region)\n",
    "print(df_best_alpha)\n",
    "dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "pickle.dump(dict_best_alpha, file)\n",
    "file.close()\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83fc4c5-d9be-4bfe-9afc-c759e08abbd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### random projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d7069e-61a6-4c43-9c06-5e48ad9868c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "             model   alpha  mean_score\n",
      "0   alexnet 10 rps   10000    0.129820\n",
      "1  alexnet 100 rps  100000    0.199531\n",
      "2  alexnet 256 rps  100000    0.208461\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_mp_rp'\n",
    "MAX_POOL = True               \n",
    "\n",
    "\n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        \n",
    "        'alexnet 10 rps':{\n",
    "                'iden':'alexnet',\n",
    "                #'model':Alexnet(num_projections=256, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'n_dims':10,\n",
    "                'alphas': [10**i for i in range(3,7)]},  \n",
    "\n",
    "\n",
    "        'alexnet 100 rps':{\n",
    "                'iden':'alexnet',\n",
    "                #'model':Alexnet(num_projections=256, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'n_dims':100,\n",
    "                'alphas': [10**i for i in range(3,7)]},  \n",
    "\n",
    "\n",
    "        'alexnet 256 rps':{\n",
    "                'iden':'alexnet',\n",
    "                #'model':Alexnet(num_projections=256, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':'rp',\n",
    "                'max_pool':MAX_POOL,\n",
    "                'n_dims':256,\n",
    "                'alphas': [10**i for i in range(3,7)]},  \n",
    "\n",
    "    \n",
    "    \n",
    "#         'alexnet 1000 rps':{\n",
    "#                 'iden':'alexnet',\n",
    "#                 #'model':Alexnet(num_projections=1000, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['last'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':256,\n",
    "#                 'dim_reduction_type':'rp',\n",
    "#                 'max_pool':MAX_POOL,\n",
    "#                 'n_dims':1000,\n",
    "#                 'alphas': [10**i for i in range(3,7)]},    \n",
    "        \n",
    "    \n",
    "         \n",
    "#         'alexnet 5000 rps':{\n",
    "#                 'iden':'alexnet',\n",
    "#                 #'model':Alexnet(num_projections=5000, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['last'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':256,\n",
    "#                 'dim_reduction_type':'rp',\n",
    "#                 'max_pool':MAX_POOL,\n",
    "#                 'n_dims':5000,\n",
    "#                 'alphas': [10**i for i in range(3,7)]}, \n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811fdac4-a17b-49dd-8297-0e28eee7ff67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Alexnet Untrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bf63a-d2be-4ac0-83f3-b853ed87fe2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d0d5cc-e071-42c9-815b-5686f32ca8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "       model  alpha  mean_score\n",
      "0  alexnet u     10    0.136087\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'alexnet_u_mp'\n",
    "MAX_POOL = True               \n",
    "\n",
    "\n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        'alexnet u':{\n",
    "                'iden':'alexnet_u',\n",
    "                #'model':AlexnetU(global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':5,\n",
    "                'num_features':256,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,4)]},   \n",
    "    \n",
    "    \n",
    "    \n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b929bb0-06bc-4c8f-9ffc-f14da82f8716",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Avg Pool Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc40778b-ea2b-44a5-8f45-3b6ec3cb7bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "                                   model  alpha  mean_score\n",
      "0     model abs 3x3 bp 224 ap 10 filters     10    0.092791\n",
      "1    model abs 3x3 bp 224 ap 100 filters     10    0.151616\n",
      "2   model abs 3x3 bp 224 ap 1000 filters     10    0.189704\n",
      "3  model abs 3x3 bp 224 ap 10000 filters     10    0.212995\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "#alpha_file_name = 'model_3L_mp'\n",
    "alpha_file_name = 'model_abs_3x3_bp_224_ap_mp'\n",
    "MAX_POOL = True               \n",
    "\n",
    "\n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "\n",
    "    \n",
    "    'model abs 3x3 bp 224 ap 10 filters':{\n",
    "                'iden':'model_abs_3x3_bp_224_ap',\n",
    "                #'model':EngModel3LAbsBPAP(filters_3 = 10, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,5)]},  \n",
    "    \n",
    "    'model abs 3x3 bp 224 ap 100 filters':{\n",
    "                'iden':'model_abs_3x3_bp_224_ap',\n",
    "                #'model':EngModel3LAbsBPAP(filters_3 = 100, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':100,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,5)]},  \n",
    "    \n",
    "    'model abs 3x3 bp 224 ap 1000 filters':{\n",
    "                'iden':'model_abs_3x3_bp_224_ap',\n",
    "                #'model':EngModel3LAbsBPAP(filters_3 = 1000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':1000,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,5)]},  \n",
    "    \n",
    "    'model abs 3x3 bp 224 ap 10000 filters':{\n",
    "                'iden':'model_abs_3x3_bp_224_ap',\n",
    "                #'model':EngModel3LAbsBPAP(filters_3 = 10000, global_mp = MAX_POOL).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessGS, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':MAX_POOL,\n",
    "                'alphas': [10**i for i in range(1,5)]},  \n",
    "\n",
    "   \n",
    "#        'alexnet u wide 10 filters':{\n",
    "#                 'iden':'alexnet_u_wide',\n",
    "#                 #'model':AlexnetUWide(filters_5 = 10, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['last'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':10,\n",
    "#                 'dim_reduction_type':None,\n",
    "#                  'max_pool':MAX_POOL,\n",
    "#                 'alphas': [10**i for i in range(1,4)]},  \n",
    "        \n",
    "    \n",
    "         \n",
    "#        'alexnet u wide 100 filters':{\n",
    "#                 'iden':'alexnet_u_wide',\n",
    "#                 #'model':AlexnetUWide(filters_5 = 100, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['last'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':100,\n",
    "#                 'dim_reduction_type':None,\n",
    "#                 'max_pool':MAX_POOL,\n",
    "#                 'alphas': [10**i for i in range(1,4)]},     \n",
    "    \n",
    "    \n",
    "#        'alexnet u wide 1000 filters':{\n",
    "#                 'iden':'alexnet_u_wide',\n",
    "#                 #'model':AlexnetUWide(filters_5 = 1000, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['last'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':1000,\n",
    "#                 'dim_reduction_type':None,\n",
    "#                 'max_pool':MAX_POOL,\n",
    "#                 'alphas': [10**i for i in range(1,4)]},  \n",
    "\n",
    "    \n",
    "    \n",
    "#        'alexnet u wide 10000 filters':{\n",
    "#                 'iden':'alexnet_u_wide',\n",
    "#                 #'model':AlexnetUWide(filters_5 = 10000, global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['last'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':10000,\n",
    "#                 'dim_reduction_type':None,\n",
    "#                  'max_pool':MAX_POOL,\n",
    "#                 'alphas': [10**i for i in range(1,4)]},   \n",
    "        \n",
    "    \n",
    "#        'alexnet':{\n",
    "#                 'iden':'alexnet',\n",
    "#                 #'model':Alexnet(global_mp = MAX_POOL).Build(),\n",
    "#                 'layers': ['last'], \n",
    "#                 'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "#                 'num_layers':5,\n",
    "#                 'num_features':256,\n",
    "#                 'dim_reduction_type':None,\n",
    "#                 'max_pool':MAX_POOL,\n",
    "#                 'alphas': [10**i for i in range(3,7)]},           \n",
    "    \n",
    "    \n",
    "       # 'alexnet u':{\n",
    "       #          'iden':'alexnet_u',\n",
    "       #          #'model':AlexnetU(global_mp = MAX_POOL).Build(),\n",
    "       #          'layers': ['last'], \n",
    "       #          'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "       #          'num_layers':5,\n",
    "       #          'num_features':256,\n",
    "       #          'dim_reduction_type':None,\n",
    "       #          'max_pool':MAX_POOL,\n",
    "       #          'alphas': [10**i for i in range(1,4)]},  \n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ac8512-1965-4612-aa7b-ac0b287e3c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4\n",
      "                          model  alpha  mean_score\n",
      "0  scattering transform kymatio     10    0.191269\n"
     ]
    }
   ],
   "source": [
    "dataset = 'naturalscenes'\n",
    "REGIONS = ['V4']\n",
    "# dataset = 'majajhong'\n",
    "# REGIONS = ['V4','IT']\n",
    "mode = 'train'\n",
    "alpha_file_name = 'scat_transform_kymatio_J3_L4_rgb'\n",
    "MAX_POOL = True               \n",
    "\n",
    "\n",
    "for region in REGIONS:\n",
    "    data_dict = {\n",
    "        \n",
    "        \n",
    "\n",
    "    'scattering transform kymatio':{\n",
    "                'iden':'scat_transform_kymatio_J3_L4_rgb',\n",
    "                #'model':ScatTransformKymatio(J = 3, L = 8, M = 32, N = 32, flatten = True, global_mp= False).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=32).PreprocessGS, \n",
    "                'num_layers':2,\n",
    "                'num_features':'x',\n",
    "                'dim_reduction_type':None,\n",
    "                'max_pool':False,\n",
    "                'alphas': [0] + [10**i for i in range(3)]},  \n",
    "    \n",
    "\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    df_best_alpha = get_best_alpha(data_dict, dataset, mode, region)\n",
    "    print(region)\n",
    "    print(df_best_alpha)\n",
    "    dict_best_alpha = df_best_alpha.set_index(['model']).to_dict()['alpha']\n",
    "    file = open(os.path.join(BEST_ALPHA_PATH, f'{alpha_file_name}_{dataset}_{region}'),'wb')\n",
    "    pickle.dump(dict_best_alpha, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5816c-a40f-44cf-8dea-2314f472b129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
