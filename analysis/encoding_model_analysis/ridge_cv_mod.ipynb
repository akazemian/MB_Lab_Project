{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b59b43-e9ff-4abe-86a9-fda26bf16645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import torch\n",
    "from sklearn.linear_model._ridge import LinearModel, MultiOutputMixin, RegressorMixin\n",
    "from sklearn.linear_model._ridge import _RidgeGCV, _BaseRidgeCV, RidgeCV\n",
    "from sklearn.linear_model._ridge import is_classifier, check_scoring, _check_gcv_mode\n",
    "from sklearn.linear_model._ridge import _IdentityRegressor, safe_sparse_dot\n",
    "\n",
    "from sklearn.metrics import r2_score, explained_variance_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "pearsonr_vec = np.vectorize(pearsonr, signature='(n),(n)->(),()')\n",
    "\n",
    "def pearson_r_score(y_true, y_pred, multioutput=None):\n",
    "    y_true_ = y_true.transpose()\n",
    "    y_pred_ = y_pred.transpose()\n",
    "    return(pearsonr_vec(y_true_, y_pred_)[0])\n",
    "\n",
    "class _RidgeGCVMod(_RidgeGCV):\n",
    "    \"\"\"Ridge regression with built-in Leave-one-out Cross-Validation.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        alphas=(0.1, 1.0, 10.0),\n",
    "        *,\n",
    "        fit_intercept=True,\n",
    "        normalize=\"deprecated\",\n",
    "        scoring=None,\n",
    "        copy_X=True,\n",
    "        gcv_mode=None,\n",
    "        store_cv_values=False,\n",
    "        is_clf=False,\n",
    "        alpha_per_target=False,\n",
    "    ):\n",
    "        self.alphas = np.asarray(alphas)\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.normalize = normalize\n",
    "        self.scoring = scoring\n",
    "        self.copy_X = copy_X\n",
    "        self.gcv_mode = gcv_mode\n",
    "        self.store_cv_values = store_cv_values\n",
    "        self.is_clf = is_clf\n",
    "        self.alpha_per_target = alpha_per_target\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        _normalize = False\n",
    "\n",
    "        X, y = self._validate_data(\n",
    "            X,\n",
    "            y,\n",
    "            accept_sparse=[\"csr\", \"csc\", \"coo\"],\n",
    "            dtype=[np.float64],\n",
    "            multi_output=True,\n",
    "            y_numeric=True,\n",
    "        )\n",
    "\n",
    "        # alpha_per_target cannot be used in classifier mode. All subclasses\n",
    "        # of _RidgeGCV that are classifiers keep alpha_per_target at its\n",
    "        # default value: False, so the condition below should never happen.\n",
    "        assert not (self.is_clf and self.alpha_per_target)\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n",
    "\n",
    "        if np.any(self.alphas <= 0):\n",
    "            raise ValueError(\n",
    "                \"alphas must be strictly positive. Got {} containing some \"\n",
    "                \"negative or null value instead.\".format(self.alphas)\n",
    "            )\n",
    "\n",
    "        X, y, X_offset, y_offset, X_scale = LinearModel._preprocess_data(\n",
    "            X,\n",
    "            y,\n",
    "            self.fit_intercept,\n",
    "            _normalize,\n",
    "            self.copy_X,\n",
    "            sample_weight=sample_weight,\n",
    "        )\n",
    "\n",
    "        gcv_mode = _check_gcv_mode(X, self.gcv_mode)\n",
    "\n",
    "        if gcv_mode == \"eigen\":\n",
    "            decompose = self._eigen_decompose_gram\n",
    "            solve = self._solve_eigen_gram\n",
    "        elif gcv_mode == \"svd\":\n",
    "            if sparse.issparse(X):\n",
    "                decompose = self._eigen_decompose_covariance\n",
    "                solve = self._solve_eigen_covariance\n",
    "            else:\n",
    "                decompose = self._svd_decompose_design_matrix\n",
    "                solve = self._solve_svd_design_matrix\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "\n",
    "        if sample_weight is not None:\n",
    "            X, y = _rescale_data(X, y, sample_weight)\n",
    "            sqrt_sw = np.sqrt(sample_weight)\n",
    "        else:\n",
    "            sqrt_sw = np.ones(n_samples, dtype=X.dtype)\n",
    "\n",
    "        X_mean, *decomposition = decompose(X, y, sqrt_sw)\n",
    "\n",
    "        if self.scoring not in ['pearson_r', 'explained_variance']:\n",
    "            raise ValueError(\"modified RidgeCV scoring requires one of ['pearson_r','explained_variance']\")\n",
    "\n",
    "        n_y = 1 if len(y.shape) == 1 else y.shape[1]\n",
    "        n_alphas = 1 if np.ndim(self.alphas) == 0 else len(self.alphas)\n",
    "\n",
    "        if self.store_cv_values:\n",
    "            self.cv_values_ = np.empty((n_samples * n_y, n_alphas), dtype=X.dtype)\n",
    "\n",
    "        best_coef, best_score, best_alpha = None, None, None\n",
    "\n",
    "        for i, alpha in enumerate(np.atleast_1d(self.alphas)):\n",
    "            G_inverse_diag, c = solve(float(alpha), y, sqrt_sw, X_mean, *decomposition)\n",
    "            predictions = y - (c / G_inverse_diag)\n",
    "            if self.store_cv_values:\n",
    "                self.cv_values_[:, i] = predictions.ravel()\n",
    "\n",
    "            identity_estimator = _IdentityRegressor()\n",
    "            if self.alpha_per_target:\n",
    "                if self.scoring == 'pearson_r':\n",
    "                    alpha_score = pearson_r_score(y, predictions)\n",
    "                if self.scoring == 'explained_variance':\n",
    "                    alpha_score = explained_variance_score(y, predictions, multioutput = 'raw_values') \n",
    "            else:\n",
    "                if self.scoring == 'pearson_r':\n",
    "                    alpha_score = pearson_r_score(y, predictions).mean()\n",
    "                if self.scoring == 'explained_variance':\n",
    "                    alpha_score = explained_variance_score(y, predictions, multioutput = 'uniform_average')\n",
    "\n",
    "            # Keep track of the best model\n",
    "            if best_score is None: \n",
    "                if self.alpha_per_target and n_y > 1:\n",
    "                    best_coef = c\n",
    "                    best_score = np.atleast_1d(alpha_score)\n",
    "                    best_alpha = np.full(n_y, alpha)\n",
    "                else:\n",
    "                    best_coef = c\n",
    "                    best_score = alpha_score\n",
    "                    best_alpha = alpha\n",
    "            else: \n",
    "                if self.alpha_per_target and n_y > 1:\n",
    "                    to_update = alpha_score > best_score\n",
    "                    best_coef[:, to_update] = c[:, to_update]\n",
    "                    best_score[to_update] = alpha_score[to_update]\n",
    "                    best_alpha[to_update] = alpha\n",
    "                elif alpha_score > best_score:\n",
    "                    best_coef, best_score, best_alpha = c, alpha_score, alpha\n",
    "\n",
    "        self.alpha_ = best_alpha\n",
    "        self.best_score_ = best_score\n",
    "        self.dual_coef_ = best_coef\n",
    "        self.coef_ = safe_sparse_dot(self.dual_coef_.T, X)\n",
    "\n",
    "        X_offset += X_mean * X_scale\n",
    "        self._set_intercept(X_offset, y_offset, X_scale)\n",
    "\n",
    "        if self.store_cv_values:\n",
    "            if len(y.shape) == 1:\n",
    "                cv_values_shape = n_samples, n_alphas\n",
    "            else:\n",
    "                cv_values_shape = n_samples, n_y, n_alphas\n",
    "            self.cv_values_ = self.cv_values_.reshape(cv_values_shape)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "class _BaseRidgeCVMod(_BaseRidgeCV):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        cv = self.cv\n",
    "        if cv is None:\n",
    "            estimator = _RidgeGCVMod(\n",
    "                self.alphas,\n",
    "                fit_intercept=self.fit_intercept,\n",
    "                normalize=self.normalize,\n",
    "                scoring=self.scoring,\n",
    "                gcv_mode=self.gcv_mode,\n",
    "                store_cv_values=self.store_cv_values,\n",
    "                is_clf=is_classifier(self),\n",
    "                alpha_per_target=self.alpha_per_target,\n",
    "            )\n",
    "            estimator.fit(X, y, sample_weight=sample_weight)\n",
    "            self.alpha_ = estimator.alpha_\n",
    "            self.best_score_ = estimator.best_score_\n",
    "            if self.store_cv_values:\n",
    "                self.cv_values_ = estimator.cv_values_\n",
    "        else:\n",
    "            if self.store_cv_values:\n",
    "                raise ValueError(\"cv!=None and store_cv_values=True are incompatible\")\n",
    "            if self.alpha_per_target:\n",
    "                raise ValueError(\"cv!=None and alpha_per_target=True are incompatible\")\n",
    "            parameters = {\"alpha\": self.alphas}\n",
    "            solver = \"sparse_cg\" if sparse.issparse(X) else \"auto\"\n",
    "            model = RidgeClassifier if is_classifier(self) else Ridge\n",
    "            gs = GridSearchCV(\n",
    "                model(\n",
    "                    fit_intercept=self.fit_intercept,\n",
    "                    normalize=self.normalize,\n",
    "                    solver=solver,\n",
    "                ),\n",
    "                parameters,\n",
    "                cv=cv,\n",
    "                scoring=self.scoring,\n",
    "            )\n",
    "            gs.fit(X, y, sample_weight=sample_weight)\n",
    "            estimator = gs.best_estimator_\n",
    "            self.alpha_ = gs.best_estimator_.alpha\n",
    "            self.best_score_ = gs.best_score_\n",
    "\n",
    "        self.coef_ = estimator.coef_\n",
    "        self.intercept_ = estimator.intercept_\n",
    "        self.n_features_in_ = estimator.n_features_in_\n",
    "        if hasattr(estimator, \"feature_names_in_\"):\n",
    "            self.feature_names_in_ = estimator.feature_names_in_\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "class RidgeCVMod(MultiOutputMixin, RegressorMixin, _BaseRidgeCVMod):\n",
    "    \"\"\"Ridge regression with built-in cross-validation.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe0a2d-9af7-43ae-8afc-5f3bcb8ca77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e83bb72-7879-4bed-b85a-e33603307b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATIONS_PATH = '/data/atlas/activations'\n",
    "activations_identifier = 'st_kymatio_j=2_2_layers_n_features_naturalscenes'\n",
    "\n",
    "activations = xr.open_dataarray(os.path.join(ACTIVATIONS_PATH,activations_identifier))  \n",
    "X = activations.values[:100,:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db33a6d8-ed51-46e7-b0e2-028e77b6b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'general'\n",
    "subject = 1\n",
    "path = f'/data/rgautha1/cache/bonner-caching/neural-dimensionality/data/dataset=allen2021.natural_scenes/resolution=1pt8mm.preprocessing=fithrf_GLMdenoise_RR/roi={region}/preprocessed/z_score=session.average_across_reps=True/subject={subject}.nc'\n",
    "var_name = f'allen2021.natural_scenes.preprocessing=fithrf_GLMdenoise_RR.roi={region}.z_score=session.average_across_reps=True.subject={subject}'\n",
    "y = xr.open_dataarray(path).values[:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d000f6-30eb-48ac-8dcf-12b4ce9b12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# these are the value of the lambda penalty in the ridge regression\n",
    "alpha_values = [100,1000,10000]\n",
    "\n",
    "# this is the regression that maps the feature space to the voxels.\n",
    "# it's a multioutput regression, so it fits all voxels simultaneously.\n",
    "# it automatically performs leave one out cross-validation ...\n",
    "# ... to choose the optimal lambda penalty. we save this loocv score\n",
    "# ... as the predictive score for the training set, but also ...\n",
    "# ... evaluate the optimal lambda regression on a heldout test set.\n",
    "regression = RidgeCVMod(alphas=alpha_values, store_cv_values = True,\n",
    "                      alpha_per_target = True, scoring = 'pearson_r')\n",
    "\n",
    "# here's where we extract the optimal lambda and generate the test predictions\n",
    "regression.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69388bbb-42a1-4d08-9ac3-d766e5abad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = X_test.dot(regression.coef_.transpose()) + regression.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85622b8d-5e7a-4174-a6eb-83be9a35486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pearson_r_score(y_test, predictions['test'], multioutput=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d57e619-39d4-4ff4-9ac5-fdd07cfb9f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
