{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e62b407e-ac0c-4340-b5b3-c432d23b6c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akazemi3/miniconda3/envs/bonner-lab-new/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/akazemi3/miniconda3/envs/bonner-lab-new/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model wrapper\n",
    "import sys\n",
    "import os\n",
    "ROOT_DIR = os.getenv('MB_ROOT_PATH')\n",
    "sys.path.append(ROOT_DIR)\n",
    "from models.all_models.model_3L_abs_blurpool_avgpool import ExpansionModel\n",
    "from models.all_models.alexnet import Alexnet\n",
    "\n",
    "from tools.loading import *\n",
    "from tools.processing import *\n",
    "import torch\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import top_k_accuracy_score as top_k\n",
    "from analysis.encoding_model_analysis.tools.utils import get_activations_iden, get_scores_iden\n",
    "from analysis.encoding_model_analysis.tools.extractor import Activations\n",
    "import torchvision\n",
    "from train import train\n",
    "\n",
    "DATA_DIR = os.getenv('MB_DATA_PATH')\n",
    "ACTIVATIONS_PATH = os.path.join(DATA_DIR,'activations') \n",
    "DATASET, MODE = 'places', None\n",
    "HOOK = 'pca'\n",
    "MAX_POOL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b99429e-cb0c-49ae-98fd-40549e5e1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_splits(n: int, num_folds: int = 5, shuffle: bool = True): \n",
    "    \n",
    "    random.seed(0)\n",
    "    if shuffle:\n",
    "        indices = np.arange(0,n)\n",
    "        random.shuffle(indices)\n",
    "    else:\n",
    "        indices = np.arange(0,n)\n",
    "\n",
    "    x = np.array_split(indices, num_folds)\n",
    "    return x\n",
    "\n",
    "def train(features, labels, estimator_type, shuffle = True, num_folds=10):\n",
    "\n",
    "    \n",
    "    splits = create_splits(n = len(features), shuffle = shuffle, num_folds=num_folds)\n",
    "    top_1, top_5 = [], []\n",
    "\n",
    "        \n",
    "    _y_true, _y_pred = [], []\n",
    "    \n",
    "    for indices_test in tqdm(splits):\n",
    "        \n",
    "        if estimator_type == 'svm':\n",
    "            classifier = svm.SVC(probability=True)\n",
    "\n",
    "\n",
    "        if estimator_type == 'logistic':\n",
    "            classifier = LogisticRegression()\n",
    "            \n",
    "\n",
    "        \n",
    "        indices_train = np.setdiff1d(np.arange(0, len(features)), np.array(indices_test))\n",
    "        X_train, y_train = features[indices_train,...], labels[indices_train,...]\n",
    "        X_test, y_test = features[indices_test,...], labels[indices_test,...]\n",
    "        print(X_train.shape, y_train.shape)\n",
    "        print(X_test.shape, y_test.shape)\n",
    "            \n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        _y_true.append(y_test)\n",
    "        _y_pred.append(y_pred)\n",
    "            \n",
    "        sum(top_5)/num_folds\n",
    "    return _y_true, _y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f4b87-52ff-43e9-96a3-fa4059aa2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expansion_model_final_mp_3_layers_10000_features_places\n",
      "array is already saved in /data/atlas/activations as expansion_model_final_mp_3_layers_10000_features_places\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 256) (8000,)\n",
      "(2000, 256) (2000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_info =   {\n",
    "                'iden':'expansion_model_final',\n",
    "                'model':ExpansionModel(filters_3=10000).Build(),\n",
    "                'layers': ['last'], \n",
    "                'preprocess':Preprocess(im_size=224).PreprocessRGB, \n",
    "                'num_layers':3,\n",
    "                'num_features':10000,\n",
    "                'max_pool':MAX_POOL,\n",
    "\n",
    "\n",
    "}\n",
    "     \n",
    " \n",
    "    \n",
    "activations_identifier = get_activations_iden(model_info, DATASET, MODE)\n",
    "print(activations_identifier)\n",
    "\n",
    "# get model activations  \n",
    "activations = Activations(model=model_info['model'],\n",
    "                        layer_names=model_info['layers'],\n",
    "                        dataset=DATASET,\n",
    "                        preprocess=model_info['preprocess'],\n",
    "                        mode = MODE,\n",
    "                        _hook = HOOK,\n",
    "                         batch_size = 50)\n",
    "\n",
    "activations.get_array(ACTIVATIONS_PATH,activations_identifier) \n",
    "\n",
    "data = xr.open_dataset(os.path.join(ACTIVATIONS_PATH,activations_identifier))\n",
    "# labels = np.array(get_places_cats())\n",
    "\n",
    "num_cats = 100\n",
    "cat_dict = load_places_cats()\n",
    "cats = np.unique(get_places_cats())\n",
    "cat_dict_subset = {k: v for k, v in cat_dict.items() if v in cats[:num_cats]}\n",
    "\n",
    "val_images_subset = list(cat_dict_subset.keys())\n",
    "data_subset = data.where(data.stimulus_id.isin(val_images_subset),drop=True)\n",
    "labels_subset = np.array([cat_dict_subset[i] for i in val_images_subset])\n",
    "    \n",
    "y_true, y_pred = train(features = np.array(data_subset.x.values), labels = labels_subset, \n",
    "                     estimator_type = 'svm', shuffle = True, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6994275d-f5dc-4e82-aa95-d13079739880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
