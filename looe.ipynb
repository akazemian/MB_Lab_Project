{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c70f8ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atlask/anaconda3/envs/bonnerlab/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/atlask/anaconda3/envs/bonnerlab/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8245c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "ROOT = os.getenv('MB_ROOT_PATH')\n",
    "DATA_PATH = os.getenv('MB_DATA_PATH')\n",
    "sys.path.append(ROOT)\n",
    "PATH_TO_NSD_SAMPLE_IDS = os.path.join(ROOT,'neural_data/nsd_sample_ids_10000')\n",
    "# NSD_PATH = os.path.join(ROOT,'datasets/allen2021.natural_scenes/images')\n",
    "# PATH_TO_NSD_SHARED_IDS = os.path.join(ROOT,'neural_data/nsd_shared_ids')\n",
    "# f = open(PATH_TO_NSD_SAMPLE_IDS,'rb')\n",
    "# sample_images = pickle.load(f)\n",
    "# f.close()\n",
    "from tools.loading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc162fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared images: False\n",
      "unshared images: True\n",
      "subset images: False\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tools.loading import *\n",
    "import pickle\n",
    "\n",
    "def generate_nsd_sample(num_samples=10000):\n",
    "    p = LoadNSDImages(unshared_images=True)\n",
    "    p_sample = random.sample(p,num_samples)\n",
    "    f = open(PATH_TO_NSD_SAMPLE_IDS,'wb')\n",
    "    pickle.dump(p_sample,f)\n",
    "\n",
    "#generate_nsd_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5167f4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5638d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared images: False\n",
      "unshared images: False\n",
      "subset images: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoadImagePaths(name='naturalscenes_zscored_processed', mode='pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f10dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(PATH_TO_NSD_SAMPLE_IDS,'rb')\n",
    "sample_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93a88c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f915987f-9495-484f-904d-5ee664e15c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/atlas/neural_data/nsd_shared_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m DATASET \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnaturalscenes_zscored_processed\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     17\u001b[0m PATH_TO_NSD_SHARED_IDS \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/data/atlas/neural_data/nsd_shared_ids\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 18\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(PATH_TO_NSD_SHARED_IDS, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m SHARED_IDS \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(file)\n\u001b[1;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bonnerlab/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/atlas/neural_data/nsd_shared_ids'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "sys.path.append(\"/home/akazemi3/Desktop/MB_Lab_Project/\") \n",
    "\n",
    "import random \n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm \n",
    "import pickle \n",
    "\n",
    "ACTIVATIONS_PATH = '/data/atlas/activations'\n",
    "NEURAL_DATA_PATH = '/data/atlas/neural_data'\n",
    "DATASET = 'naturalscenes_zscored_processed'\n",
    "\n",
    "PATH_TO_NSD_SHARED_IDS = '/data/atlas/neural_data/nsd_shared_ids'\n",
    "file = open(PATH_TO_NSD_SHARED_IDS, 'rb')\n",
    "SHARED_IDS = pickle.load(file)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy\n",
    "from sklearn.preprocessing import scale\n",
    "from tools.loading import *\n",
    "from sklearn.linear_model import Ridge\n",
    "from analysis.neural_data_regression.tools.scorers.function_types import Regression\n",
    "from analysis.neural_data_regression.tools.regression import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34504fdf-7892-47de-ac52-98db61b7c75b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m RidgeCV\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "def RR_looe_demo(X_training, Y_training, alphas):\n",
    "    \"\"\" Implements the ridge regression SVD-based LOOE estimate\n",
    "    from http://cbcl.mit.edu/publications/ps/MIT-CSAIL-TR-2007-025.pdf, page 6\n",
    "    args:\n",
    "    X_training (np.ndarray) n_obs x n_features\n",
    "    Y_training (np.ndarray) n_obs x n_targets\n",
    "    alpha (iterable) n_alphas\n",
    "    returns\n",
    "    np.ndarray ( n_targets x n_alphas)\n",
    "    ! assumes the columns of X_training and Y_training are centered\n",
    "    \"\"\"\n",
    "\n",
    "    n_training = X_training.shape[0]\n",
    "    n_targets =  Y_training.shape[1]\n",
    "    n_alphas = len(alphas)\n",
    "\n",
    "    [U,s,Vh] = scipy.linalg.svd(X_training,full_matrices=False,overwrite_a=False)\n",
    "    del Vh, X_training\n",
    "\n",
    "    I = np.eye(n_training)\n",
    "    columnwise_mean_squared=lambda x: (x**2).mean(axis=0)\n",
    "\n",
    "    looe = np.ones((n_targets,n_alphas))*np.nan\n",
    "\n",
    "    for i_alpha, alpha in enumerate(alphas):\n",
    "        # rewriting the LOOE equation from page 6 as AY/diag(A)\n",
    "\n",
    "        #S_bar=np.diag(1/(s**2+alpha)-1/alpha)\n",
    "        S_bar=np.diag(-(s**2)/(alpha*s**2+alpha**2)) # equivalent to the previous line but less prone to underflow when s is very small\n",
    "        A=U@S_bar@U.T+I/alpha\n",
    "\n",
    "        looe[:,i_alpha]=columnwise_mean_squared(\n",
    "                            (A@Y_training)\n",
    "                            / np.reshape(np.diag(A),(-1,1)))\n",
    "    return looe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbca666-e01d-4059-b332-9dfadab9b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nsd_data(mode: str, subject: int, region: str, return_ids: bool = True) -> torch.Tensor:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Loads the neural data from disk for a particular subject and region.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mode:\n",
    "            The type of neural data to load ('shared' or 'unshared')\n",
    "            \n",
    "        subject:\n",
    "            The subject number \n",
    "        \n",
    "        region:\n",
    "            The region name\n",
    "            \n",
    "        return_ids: \n",
    "            Whether the image ids are returned \n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A Tensor of Neural data, or Tensor of Neural data and stimulus ids\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        file_name = f'subject_{subject}_{region}'\n",
    "        file_path = os.path.join(NEURAL_DATA_PATH,DATASET,file_name)\n",
    "\n",
    "        if mode == 'unshared':\n",
    "            file_ext = '_unshared_new.nc'\n",
    "\n",
    "        elif mode == 'shared':\n",
    "            file_ext = '_shared_new.nc'\n",
    "\n",
    "        data = xr.open_dataset(file_path + file_ext)\n",
    "        ids = list(data.stimulus_id.values)\n",
    "        data = torch.Tensor(data['x'].values).transpose(0,1)\n",
    "        \n",
    "        if return_ids:\n",
    "            return ids, data\n",
    "        else:\n",
    "            return data\n",
    "           \n",
    "        \n",
    "        \n",
    "            \n",
    "def filter_activations(data: xr.DataArray, ids: list) -> torch.Tensor:\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "        Filters model activations using image ids.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data:\n",
    "            Model activation data\n",
    "            \n",
    "        ids:\n",
    "            image ids\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A Tensor of model activations filtered by image ids\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        data = data.set_index({'presentation':'stimulus_id'})\n",
    "        activations = data.sel(presentation=ids)\n",
    "        activations = activations.sortby('presentation', ascending=True)\n",
    "\n",
    "        return torch.Tensor(activations.values)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a36e1fb1-0c3c-4e3a-8415-acd7c01909f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f1532924396d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             y_true, y_predicted = regression_cv(x=X,\n\u001b[0m\u001b[1;32m     41\u001b[0m                                                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregression_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = 'model_3L_mp_1000'\n",
    "activations_identifier = 'model_3L_mp_1000' + '_naturalscenes_zscored_processed'\n",
    "region = 'V4'\n",
    "alphas = [10,100,1000]   \n",
    "activations_data = xr.open_dataarray(os.path.join(ACTIVATIONS_PATH,activations_identifier))         \n",
    "\n",
    "\n",
    "ds = xr.Dataset(data_vars=dict(r_value=([\"r_values\"], [])),\n",
    "                            coords={'subject': (['r_values'], []),\n",
    "                                    'region': (['r_values'], [])\n",
    "                                     })\n",
    "\n",
    "l = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    regression_model = Ridge(alpha = alpha)\n",
    "    for subject in range(8):\n",
    "\n",
    "            print('subject: ',subject)\n",
    "\n",
    "            ids, y = load_nsd_data(mode ='unshared',\n",
    "                                   subject = subject,\n",
    "                                   region = region,\n",
    "                                   return_ids = True)\n",
    "\n",
    "\n",
    "                \n",
    "            idx = np.random.randint(0,len(ids),35000)\n",
    "            sampled_ids = np.array(ids)[idx]\n",
    "\n",
    "            X_sample = filter_activations(data = activations_data,\n",
    "                                   ids = sampled_ids)\n",
    "\n",
    "            y_sample = y[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            y_true, y_predicted = regression_cv(x=X,\n",
    "                                                y=y,\n",
    "                                                model=regression_model,\n",
    "                                                save_betas=False,\n",
    "                                                scores_identifier='')\n",
    "            r =  torch.stack(\n",
    "               [pearson_r(y_true_, y_predicted_) for y_true_, y_predicted_ in zip(y_true, y_predicted)]\n",
    "            ).mean(dim=0)\n",
    "\n",
    "\n",
    "            print(r.mean())\n",
    "            subject_list = [subject for i in range(len(r))]\n",
    "            region_list = [region for i in range(len(r))]\n",
    "\n",
    "            ds_tmp = xr.Dataset(data_vars=dict(r_value=([\"r_values\"], r)),\n",
    "                                        coords={'subject': (['r_values'], subject_list),\n",
    "                                                'region': (['r_values'], region_list)\n",
    "                                                 })\n",
    "\n",
    "            ds = xr.concat([ds,ds_tmp],dim='r_values')\n",
    "    l.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d726b477-c9a1-4523-8d6a-345516cfdd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.0453750e-01, -9.1948675e-04,  6.9110566e-01, ...,\n",
       "         1.8597763e+00, -2.4656360e-01, -5.5316508e-01],\n",
       "       [ 5.1491678e-01, -2.1221349e-01, -2.3578423e-01, ...,\n",
       "        -3.0695957e-01, -1.4389749e+00,  3.3256328e-01],\n",
       "       [-5.7884341e-01, -2.4045575e-01, -3.5428324e-01, ...,\n",
       "        -1.7558341e-01, -1.3365078e+00, -5.8807856e-01],\n",
       "       ...,\n",
       "       [-2.7613586e-01, -3.0635437e-01, -4.3707019e-01, ...,\n",
       "         6.2626410e-01, -1.7977032e-01,  1.2254518e-01],\n",
       "       [ 7.2396898e-01,  8.1601435e-01,  1.4000392e-01, ...,\n",
       "        -2.1959125e-01, -8.5984707e-01,  2.1869144e-01],\n",
       "       [ 1.9891516e+00, -8.0425519e-01, -6.4160275e-01, ...,\n",
       "        -1.7973989e+00, -6.1999851e-01, -7.5297761e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a393e9-25c7-4113-aec9-3ee9aaf9fa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['image46133', 'image51137', 'image32437', ..., 'image37056',\n",
       "       'image52179', 'image06768'], dtype='<U10')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sampled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4171012-98aa-432c-92c5-0d36ecca9a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['image42504', 'image68844', 'image40959', ..., 'image19682',\n",
       "       'image28680', 'image12596'], dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sampled_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd98d500-70c6-4b0d-8ad8-2dffd4f4a14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6513, 4232, 2535, ..., 1443, 5372, 5107])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbdf63ca-32f3-439c-8495-695a84495a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 <xarray.DataArray 'r_value' ()>\n",
      "array(0.16528444)\n",
      "100 <xarray.DataArray 'r_value' ()>\n",
      "array(0.17630017)\n",
      "1000 <xarray.DataArray 'r_value' ()>\n",
      "array(0.17537826)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(l)):\n",
    "    print(alphas[i], l[i].r_value.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b792705-bf1b-457c-9d12-d5a9cf2958b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
