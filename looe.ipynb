{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f915987f-9495-484f-904d-5ee664e15c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "sys.path.append(\"/home/akazemi3/Desktop/MB_Lab_Project/\") \n",
    "\n",
    "import random \n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm \n",
    "import pickle \n",
    "\n",
    "ACTIVATIONS_PATH = '/data/atlas/activations'\n",
    "NEURAL_DATA_PATH = '/data/atlas/neural_data'\n",
    "DATASET = 'naturalscenes_zscored_processed'\n",
    "\n",
    "PATH_TO_NSD_SHARED_IDS = '/data/atlas/neural_data/nsd_shared_ids'\n",
    "file = open(PATH_TO_NSD_SHARED_IDS, 'rb')\n",
    "SHARED_IDS = pickle.load(file)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scipy\n",
    "from sklearn.preprocessing import scale\n",
    "from tools.loading import *\n",
    "from sklearn.linear_model import Ridge\n",
    "from analysis.neural_data_regression.tools.scorers.function_types import Regression\n",
    "from analysis.neural_data_regression.tools.regression import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34504fdf-7892-47de-ac52-98db61b7c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "def RR_looe_demo(X_training, Y_training, alphas):\n",
    "    \"\"\" Implements the ridge regression SVD-based LOOE estimate\n",
    "    from http://cbcl.mit.edu/publications/ps/MIT-CSAIL-TR-2007-025.pdf, page 6\n",
    "    args:\n",
    "    X_training (np.ndarray) n_obs x n_features\n",
    "    Y_training (np.ndarray) n_obs x n_targets\n",
    "    alpha (iterable) n_alphas\n",
    "    returns\n",
    "    np.ndarray ( n_targets x n_alphas)\n",
    "    ! assumes the columns of X_training and Y_training are centered\n",
    "    \"\"\"\n",
    "\n",
    "    n_training = X_training.shape[0]\n",
    "    n_targets =  Y_training.shape[1]\n",
    "    n_alphas = len(alphas)\n",
    "\n",
    "    [U,s,Vh] = scipy.linalg.svd(X_training,full_matrices=False,overwrite_a=False)\n",
    "    del Vh, X_training\n",
    "\n",
    "    I = np.eye(n_training)\n",
    "    columnwise_mean_squared=lambda x: (x**2).mean(axis=0)\n",
    "\n",
    "    looe = np.ones((n_targets,n_alphas))*np.nan\n",
    "\n",
    "    for i_alpha, alpha in enumerate(alphas):\n",
    "        # rewriting the LOOE equation from page 6 as AY/diag(A)\n",
    "\n",
    "        #S_bar=np.diag(1/(s**2+alpha)-1/alpha)\n",
    "        S_bar=np.diag(-(s**2)/(alpha*s**2+alpha**2)) # equivalent to the previous line but less prone to underflow when s is very small\n",
    "        A=U@S_bar@U.T+I/alpha\n",
    "\n",
    "        looe[:,i_alpha]=columnwise_mean_squared(\n",
    "                            (A@Y_training)\n",
    "                            / np.reshape(np.diag(A),(-1,1)))\n",
    "    return looe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbca666-e01d-4059-b332-9dfadab9b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nsd_data(mode: str, subject: int, region: str, return_ids: bool = True) -> torch.Tensor:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Loads the neural data from disk for a particular subject and region.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mode:\n",
    "            The type of neural data to load ('shared' or 'unshared')\n",
    "            \n",
    "        subject:\n",
    "            The subject number \n",
    "        \n",
    "        region:\n",
    "            The region name\n",
    "            \n",
    "        return_ids: \n",
    "            Whether the image ids are returned \n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A Tensor of Neural data, or Tensor of Neural data and stimulus ids\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        file_name = f'subject_{subject}_{region}'\n",
    "        file_path = os.path.join(NEURAL_DATA_PATH,DATASET,file_name)\n",
    "\n",
    "        if mode == 'unshared':\n",
    "            file_ext = '_unshared_new.nc'\n",
    "\n",
    "        elif mode == 'shared':\n",
    "            file_ext = '_shared_new.nc'\n",
    "\n",
    "        data = xr.open_dataset(file_path + file_ext)\n",
    "        ids = list(data.stimulus_id.values)\n",
    "        data = torch.Tensor(data['x'].values).transpose(0,1)\n",
    "        \n",
    "        if return_ids:\n",
    "            return ids, data\n",
    "        else:\n",
    "            return data\n",
    "           \n",
    "        \n",
    "        \n",
    "            \n",
    "def filter_activations(data: xr.DataArray, ids: list) -> torch.Tensor:\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "        Filters model activations using image ids.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data:\n",
    "            Model activation data\n",
    "            \n",
    "        ids:\n",
    "            image ids\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A Tensor of model activations filtered by image ids\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        data = data.set_index({'presentation':'stimulus_id'})\n",
    "        activations = data.sel(presentation=ids)\n",
    "        activations = activations.sortby('presentation', ascending=True)\n",
    "\n",
    "        return torch.Tensor(activations.values)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a36e1fb1-0c3c-4e3a-8415-acd7c01909f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f1532924396d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             y_true, y_predicted = regression_cv(x=X,\n\u001b[0m\u001b[1;32m     41\u001b[0m                                                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregression_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = 'model_3L_mp_1000'\n",
    "activations_identifier = 'model_3L_mp_1000' + '_naturalscenes_zscored_processed'\n",
    "region = 'V4'\n",
    "alphas = [10,100,1000]   \n",
    "activations_data = xr.open_dataarray(os.path.join(ACTIVATIONS_PATH,activations_identifier))         \n",
    "\n",
    "\n",
    "ds = xr.Dataset(data_vars=dict(r_value=([\"r_values\"], [])),\n",
    "                            coords={'subject': (['r_values'], []),\n",
    "                                    'region': (['r_values'], [])\n",
    "                                     })\n",
    "\n",
    "l = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    regression_model = Ridge(alpha = alpha)\n",
    "    for subject in range(8):\n",
    "\n",
    "            print('subject: ',subject)\n",
    "\n",
    "            ids, y = load_nsd_data(mode ='unshared',\n",
    "                                   subject = subject,\n",
    "                                   region = region,\n",
    "                                   return_ids = True)\n",
    "\n",
    "\n",
    "                \n",
    "            idx = np.random.randint(0,len(ids),35000)\n",
    "            sampled_ids = np.array(ids)[idx]\n",
    "\n",
    "            X_sample = filter_activations(data = activations_data,\n",
    "                                   ids = sampled_ids)\n",
    "\n",
    "            y_sample = y[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            y_true, y_predicted = regression_cv(x=X,\n",
    "                                                y=y,\n",
    "                                                model=regression_model,\n",
    "                                                save_betas=False,\n",
    "                                                scores_identifier='')\n",
    "            r =  torch.stack(\n",
    "               [pearson_r(y_true_, y_predicted_) for y_true_, y_predicted_ in zip(y_true, y_predicted)]\n",
    "            ).mean(dim=0)\n",
    "\n",
    "\n",
    "            print(r.mean())\n",
    "            subject_list = [subject for i in range(len(r))]\n",
    "            region_list = [region for i in range(len(r))]\n",
    "\n",
    "            ds_tmp = xr.Dataset(data_vars=dict(r_value=([\"r_values\"], r)),\n",
    "                                        coords={'subject': (['r_values'], subject_list),\n",
    "                                                'region': (['r_values'], region_list)\n",
    "                                                 })\n",
    "\n",
    "            ds = xr.concat([ds,ds_tmp],dim='r_values')\n",
    "    l.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d726b477-c9a1-4523-8d6a-345516cfdd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.0453750e-01, -9.1948675e-04,  6.9110566e-01, ...,\n",
       "         1.8597763e+00, -2.4656360e-01, -5.5316508e-01],\n",
       "       [ 5.1491678e-01, -2.1221349e-01, -2.3578423e-01, ...,\n",
       "        -3.0695957e-01, -1.4389749e+00,  3.3256328e-01],\n",
       "       [-5.7884341e-01, -2.4045575e-01, -3.5428324e-01, ...,\n",
       "        -1.7558341e-01, -1.3365078e+00, -5.8807856e-01],\n",
       "       ...,\n",
       "       [-2.7613586e-01, -3.0635437e-01, -4.3707019e-01, ...,\n",
       "         6.2626410e-01, -1.7977032e-01,  1.2254518e-01],\n",
       "       [ 7.2396898e-01,  8.1601435e-01,  1.4000392e-01, ...,\n",
       "        -2.1959125e-01, -8.5984707e-01,  2.1869144e-01],\n",
       "       [ 1.9891516e+00, -8.0425519e-01, -6.4160275e-01, ...,\n",
       "        -1.7973989e+00, -6.1999851e-01, -7.5297761e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33a393e9-25c7-4113-aec9-3ee9aaf9fa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['image46133', 'image51137', 'image32437', ..., 'image37056',\n",
       "       'image52179', 'image06768'], dtype='<U10')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sampled_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4171012-98aa-432c-92c5-0d36ecca9a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['image42504', 'image68844', 'image40959', ..., 'image19682',\n",
       "       'image28680', 'image12596'], dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sampled_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd98d500-70c6-4b0d-8ad8-2dffd4f4a14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6513, 4232, 2535, ..., 1443, 5372, 5107])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbdf63ca-32f3-439c-8495-695a84495a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 <xarray.DataArray 'r_value' ()>\n",
      "array(0.16528444)\n",
      "100 <xarray.DataArray 'r_value' ()>\n",
      "array(0.17630017)\n",
      "1000 <xarray.DataArray 'r_value' ()>\n",
      "array(0.17537826)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(l)):\n",
    "    print(alphas[i], l[i].r_value.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b792705-bf1b-457c-9d12-d5a9cf2958b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
