{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e99237-7a7b-4047-a265-ee72dec7d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "sys.path.append(os.getenv('MODELS_ROOT_PATH'))\n",
    "\n",
    "from expansion import Expansion5L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc941ef-6f0d-417f-8d63-c816475431e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define your desired mean and variance\n",
    "specified_mean = torch.tensor([0.5, 0.5])  # Replace with your desired mean\n",
    "specified_var = torch.tensor([0.2, 0.2])   # Replace with your desired variance\n",
    "\n",
    "# Assuming your input data has shape (batch_size, num_channels, height, width)\n",
    "num_channels = 3  # Replace with the number of channels in your data\n",
    "height = 32  # Replace with the height of your data\n",
    "width = 32  # Replace with the width of your data\n",
    "\n",
    "# Create a BatchNorm2d layer with specified mean and variance\n",
    "\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cbb00e-4081-4f6e-82ad-c1de4f93e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from layer_operations.convolution import Convolution, initialize_conv_layer\n",
    "from layer_operations.output import Output\n",
    "from layer_operations.nonlinearity import NonLinearity\n",
    "import math\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)                        \n",
    "  \n",
    "\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self,\n",
    "                conv1: nn.Module,\n",
    "                pool1: nn.Module,\n",
    "                conv2: nn.Module,\n",
    "                pool2: nn.Module,\n",
    "                conv3: nn.Module,\n",
    "                pool3: nn.Module,\n",
    "                conv4: nn.Module,\n",
    "                pool4: nn.Module,\n",
    "                conv5: nn.Module,\n",
    "                pool5: nn.Module,\n",
    "                nl: nn.Module,\n",
    "                gpool: bool,\n",
    "                last: nn.Module,\n",
    "                specified_var,\n",
    "                specified_var\n",
    "                ):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = conv1 \n",
    "        self.pool1 = pool1\n",
    "        \n",
    "        self.conv2 = conv2\n",
    "        self.pool2 = pool2\n",
    "        \n",
    "        self.conv3 = conv3\n",
    "        self.pool3 = pool3\n",
    "\n",
    "        self.conv4 = conv4\n",
    "        self.pool4 = pool4\n",
    "        \n",
    "        self.conv5 = conv5\n",
    "        self.pool5 = pool5\n",
    "        \n",
    "        self.nl = nl\n",
    "        self.gpool = gpool\n",
    "        self.last = last\n",
    "        \n",
    "        self.specified_mean = specified_mean\n",
    "        self.specified_var = specified_var\n",
    "    \n",
    "    \n",
    "    def forward(self, x:nn.Module):         \n",
    "   \n",
    "        \n",
    "        #layer 1 \n",
    "        x = self.conv1(x)  # conv \n",
    "        x = self.nl(x) # non linearity \n",
    "        x = self.pool1(x) # anti-aliasing blurpool  \n",
    "        print('1', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "        batch_norm = nn.BatchNorm2d(x.shape[1])\n",
    "        batch_norm.running_mean = nn.Parameter(self.specified_mean)\n",
    "        batch_norm.running_var = nn.Parameter(self.specified_var)\n",
    "        x = batch_norm(x)\n",
    "        print('1 after batchnorm', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "        \n",
    "        #layer 2\n",
    "        x = self.conv2(x)  \n",
    "        x = self.nl(x) \n",
    "        x = self.pool2(x) \n",
    "        print('2', ' mean:',x.mean().detach().cpu().numpy(), ' std:',x.std().cpu().detach().numpy())    \n",
    "        batch_norm = nn.BatchNorm2d(x.shape[1])\n",
    "        batch_norm.running_mean = nn.Parameter(self.specified_mean)\n",
    "        batch_norm.running_var = nn.Parameter(self.specified_var)\n",
    "        x = batch_norm(x)\n",
    "        print('2 after batchnorm', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "        \n",
    "        #layer 3\n",
    "        x = self.conv3(x)  \n",
    "        x = self.nl(x) \n",
    "        x = self.pool3(x) \n",
    "        print('3', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "        batch_norm = nn.BatchNorm2d(x.shape[1])\n",
    "        batch_norm.running_mean = nn.Parameter(self.specified_mean)\n",
    "        batch_norm.running_var = nn.Parameter(self.specified_var)\n",
    "        x = batch_norm(x)\n",
    "        print('3 after batchnorm', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "\n",
    "        #layer 4\n",
    "        x = self.conv4(x)  \n",
    "        x = self.nl(x) \n",
    "        x = self.pool4(x) \n",
    "        print('4', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "        batch_norm = nn.BatchNorm2d(x.shape[1])\n",
    "        batch_norm.running_mean = nn.Parameter(self.specified_mean)\n",
    "        batch_norm.running_var = nn.Parameter(self.specified_var)\n",
    "        x = batch_norm(x)\n",
    "        print('4 after batchnorm', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "\n",
    "        #layer 5\n",
    "        x = self.conv5(x)  \n",
    "        x = self.nl(x) \n",
    "        x = self.pool5(x)  \n",
    "        print('5', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "        batch_norm = nn.BatchNorm2d(x.shape[1])\n",
    "        batch_norm.running_mean = nn.Parameter(self.specified_mean)\n",
    "        batch_norm.running_var = nn.Parameter(self.specified_var)\n",
    "        x = batch_norm(x)\n",
    "        print('5 after batchnorm', ' mean:',x.mean().cpu().detach().numpy(), ' std:',x.std().cpu().detach().numpy())\n",
    "        \n",
    "        if self.gpool: # global pool\n",
    "            H = x.shape[-1]\n",
    "            gmp = nn.AvgPool2d(H) \n",
    "            x = gmp(x)\n",
    "        \n",
    "        x = self.last(x) # final layer\n",
    "        \n",
    "        return x    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class Expansion5L:\n",
    "    def __init__(self, \n",
    "                 filters_1_type:str='curvature',\n",
    "                 filters_1_params:dict = {'n_ories':12,'n_curves':3,'gau_sizes':(5,),'spatial_fre':[1.2]},\n",
    "                 filters_2:int=1000,\n",
    "                 filters_3:int=3000,\n",
    "                 filters_4:int=5000,\n",
    "                 filters_5:int=30000,\n",
    "                 init_type:str = 'kaiming_uniform',\n",
    "                 gpool:bool=False,\n",
    "                 non_linearity:str='relu',\n",
    "                 device:str='cuda',\n",
    "                 specified_var=None,\n",
    "                 specified_var=None):    \n",
    "        \n",
    "        self.filters_1_type = filters_1_type\n",
    "        self.filters_1_params = filters_1_params\n",
    "        \n",
    "        match self.filters_1_type:\n",
    "        \n",
    "            case 'curvature':\n",
    "                self.filters_1 = self.filters_1_params['n_ories']*self.filters_1_params['n_curves']*len(self.filters_1_params['gau_sizes']*len(self.filters_1_params['spatial_fre']))*3\n",
    "            case 'gabor':\n",
    "                self.filters_1 = self.filters_1_params['n_ories']*self.filters_1_params['num_scales']*3\n",
    "            case 'random':\n",
    "                self.filters_1 = self.filters_1_params['filters']\n",
    "        \n",
    "        self.filters_2 = filters_2\n",
    "        self.filters_3 = filters_3\n",
    "        self.filters_4 = filters_4\n",
    "        self.filters_5 = filters_5\n",
    "        self.init_type = init_type\n",
    "        self.gpool = gpool\n",
    "        self.non_linearity = non_linearity\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        features = xr.open_dataset(f'/data/atlas/.cache/activations/expansion_features={self.filters_5}_layers=5_dataset=naturalscenes_{self.init_type}',engine='netcdf4')\n",
    "        self.specified_mean = features.x.values.mean()\n",
    "        self.specified_var = features.x.values.var()      \n",
    "\n",
    "    def create_layer(self, in_filters, out_filters, kernel_size, stride=1, pool_kernel=2, pool_stride=None,padding=0):\n",
    "        conv = nn.Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride= stride, padding = padding, bias=False).to(self.device)\n",
    "        initialize_conv_layer(conv, self.init_type)\n",
    "        pool = nn.AvgPool2d(kernel_size=pool_kernel, stride=pool_stride)\n",
    "        return conv, pool\n",
    "\n",
    "    def Build(self):\n",
    "        \n",
    "        # layer 1\n",
    "        if self.filters_1_type != 'random':\n",
    "            conv1 = Convolution(filter_size=15, filter_type=self.filters_1_type, filter_params=self.filters_1_params, device = self.device)\n",
    "            pool1 =  nn.AvgPool2d(kernel_size=2)\n",
    "        else:\n",
    "            conv1, pool1 = self.create_layer(3, self.filters_1, (15, 15), 1, 2, padding = math.floor(15 / 2))\n",
    "\n",
    "        # layer 2 to 5\n",
    "        conv2, pool2 = self.create_layer(self.filters_1, self.filters_2, (7, 7), 1, 2)\n",
    "        conv3, pool3 = self.create_layer(self.filters_2, self.filters_3, (5, 5), 1, 2)\n",
    "        conv4, pool4 = self.create_layer(self.filters_3, self.filters_4, (3, 3), 1, 2)\n",
    "        conv5, pool5 = self.create_layer(self.filters_4, self.filters_5, (3, 3), 1, 4, 1)\n",
    "\n",
    "        nl = NonLinearity(self.non_linearity)\n",
    "        last = Output()\n",
    "\n",
    "        return Model(\n",
    "            conv1, pool1, conv2, pool2, conv3, pool3, conv4, pool4, conv5, pool5, nl, self.gpool, last,self.specified_mean,self.specified_var\n",
    "        )\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d24243bc-a067-427f-83b4-f9aa1ab6d0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaiming_normal\n",
      "0.106800586\n",
      "0.023265777\n",
      "1  mean: 0.12137948  std: 0.10409153\n",
      "2  mean: 0.085274346  std: 0.101818874\n",
      "3  mean: 0.073120095  std: 0.10050995\n",
      "4  mean: 0.07022164  std: 0.100529306\n",
      "5  mean: 0.075251274  std: 0.1011363\n",
      "orthogonal\n",
      "0.03441133\n",
      "0.0021027813\n",
      "1  mean: 0.12137948  std: 0.10409153\n",
      "2  mean: 0.060733706  std: 0.071307\n",
      "3  mean: 0.03699775  std: 0.05094464\n",
      "4  mean: 0.024848795  std: 0.036261342\n",
      "5  mean: 0.016003553  std: 0.02495929\n",
      "xavier_uniform\n",
      "0.010577467\n",
      "0.000266894\n",
      "1  mean: 0.12137948  std: 0.10409153\n",
      "2  mean: 0.027248397  std: 0.031369735\n",
      "3  mean: 0.011451066  std: 0.016160304\n",
      "4  mean: 0.006871093  std: 0.009850632\n",
      "5  mean: 0.0064739743  std: 0.009817692\n",
      "xavier_normal\n",
      "0.010685693\n",
      "0.00021753633\n",
      "1  mean: 0.12137948  std: 0.10409153\n",
      "2  mean: 0.027520007  std: 0.03115738\n",
      "3  mean: 0.011485374  std: 0.015762325\n",
      "4  mean: 0.0068306527  std: 0.009772685\n",
      "5  mean: 0.0073236693  std: 0.010162156\n",
      "uniform\n",
      "1286186900000000.0\n",
      "2.754695e+29\n",
      "1  mean: 0.12137948  std: 0.10409153\n",
      "2  mean: 314.77942  std: 8.94816\n",
      "3  mean: 3915014.2  std: 53927.355\n",
      "4  mean: 52784920000.0  std: 504588160.0\n",
      "5  mean: 1185306600000000.0  std: 4097708700000.0\n",
      "normal\n",
      "12747900.0\n",
      "309394950000000.0\n",
      "1  mean: 0.12137948  std: 0.10409153\n",
      "2  mean: 4.4154077  std: 5.247911\n",
      "3  mean: 440.15503  std: 604.86383\n",
      "4  mean: 48923.55  std: 70846.414\n",
      "5  mean: 7028498.5  std: 10742580.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = torch.rand(1,3,224,224)\n",
    "\n",
    "device = 'cuda'\n",
    "TYPES = ['kaiming_normal', 'orthogonal', 'xavier_uniform', 'xavier_normal', 'uniform','normal']\n",
    "\n",
    "for init_type in TYPES:\n",
    "    #features = xr.open_dataset(f'/data/atlas/.cache/activations/expansion_features=300_layers=5_dataset=naturalscenes_{init_type}',engine='netcdf4')\n",
    "    expansion_model = Expansion5L(filters_5 = 300, # number of filters in the last convolution layer of the mdoel\n",
    "                              init_type = init_type, #initialization type used for random filters\n",
    "                              non_linearity='relu',\n",
    "                              gpool = False, # whether global pooling is applied oto the output \n",
    "                              device=device).Build()\n",
    "\n",
    "    print(init_type)\n",
    "    features = xr.open_dataset(f'/data/atlas/.cache/activations/expansion_features=300_layers=5_dataset=naturalscenes_{init_type}',engine='netcdf4')\n",
    "    print(features.x.values.mean())\n",
    "    print(features.x.values.var())\n",
    "    \n",
    "    features = expansion_model(image.to(device))\n",
    "    #print(f'{init_type}:', ' mean:',features.mean().detach().numpy(), ' std:',features.std().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f703d42-97f9-4ea6-959c-8a20591deaa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/atlas/.cache/activations/expansion_features=300_layers=5_dataset=naturalscenes_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43minit_type\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetcdf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mvar())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_type' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c908320-e3d8-4ec7-a015-ebd6e251c7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cfaad-c2b9-4563-9a8c-407571946f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd20fc-6312-4da8-ba78-5a260e29cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "'categories_places365.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ef6ef-89cb-45a9-ad57-02f2bbc8a892",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Untrained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee056f69-cfbc-4330-b8ab-a05514f04cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ToSplitTensor()\n",
      "  (1): Sequential(\n",
      "    (0): Scattering2D(input_channels=3R, S=1, L=8, spatial=(224,224) to (112,112), phi_channels=3R, psi_channels=24C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(27,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=27R, out_channels=32R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Scattering2D(input_channels=32R, S=1, L=8, spatial=(112,112) to (112,112), phi_channels=32R, psi_channels=256C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(288,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=288R, out_channels=64R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Scattering2D(input_channels=64R, S=1, L=8, spatial=(112,112) to (56,56), phi_channels=64R, psi_channels=512C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(576,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=576R, out_channels=64R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Scattering2D(input_channels=64R, S=1, L=8, spatial=(56,56) to (56,56), phi_channels=64R, psi_channels=512C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(576,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=576R, out_channels=128R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Scattering2D(input_channels=128R, S=1, L=8, spatial=(56,56) to (28,28), phi_channels=128R, psi_channels=1024C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(1152,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=1152R, out_channels=256R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Scattering2D(input_channels=256R, S=1, L=8, spatial=(28,28) to (28,28), phi_channels=256R, psi_channels=2048C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(2304,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=2304R, out_channels=512R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(28,28) to (14,14), phi_channels=512R, psi_channels=4096C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=4608R, out_channels=512R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (8): Sequential(\n",
      "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(14,14) to (14,14), phi_channels=512R, psi_channels=4096C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=4608R, out_channels=512R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (9): Sequential(\n",
      "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(14,14) to (7,7), phi_channels=512R, psi_channels=4096C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=4608R, out_channels=512R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (10): Sequential(\n",
      "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(7,7) to (6,6), phi_channels=512R, psi_channels=4096C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=4608R, out_channels=512R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (11): Sequential(\n",
      "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(6,6) to (3,3), phi_channels=512R, psi_channels=4096C)\n",
      "    (1): Branching(\n",
      "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
      "    )\n",
      "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
      "    (3): DiagonalModule(ModuleDict(\n",
      "      (0): ComplexConv2d(in_channels=4608R, out_channels=256R, complex_weights=False)\n",
      "    ))\n",
      "    (4): DiagonalModule(ModuleDict(\n",
      "      (0): Normalization(dim=1, p=2)\n",
      "    ))\n",
      "  )\n",
      "  (12): ToTensor()\n",
      "  (13): Classifier(\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (classifier): Linear(in_features=2304, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8133f7e7-b2d5-44db-bf7d-728e317783fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [32, 128, 256, 512, 1024, 2048, 4096, 8192] \n",
    "name = str(l[0])\n",
    "for i in l[1:]:\n",
    "    name += f'_{i}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c59e8a-2c87-45a3-9567-2081ce316690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_features.models.learned_scaterring.main_custom import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d83287-ec5a-485e-94c6-20da9d2590ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30938a01-fef0-4695-bb6f-79d6df101572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d37854d-a0a4-4911-b63f-ca28883648a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8192, 14, 14])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(1,3,224,224)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a35c81-b9df-410d-a3d0-2d0b66611abe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b89dfb-ead4-493d-a4b7-5dd2118eb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "num_layers = 11\n",
    "\n",
    "path = '/data/atlas/rainbow_models/Pr_Norm/batchsize_128_lrfreq_45_best.pth.tar'\n",
    "model = load_model()\n",
    "checkpoint = torch.load(path)\n",
    "state_dict = checkpoint[\"state_dict\"]\n",
    "state_dict = {key.replace(\"(0, 0)\", \"0\"): value for key, value in state_dict.items()}\n",
    "checkpoint[\"state_dict\"] = state_dict\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "m = model[:num_layers+1]\n",
    "\n",
    "\n",
    "num_params = 0\n",
    "for layer in range(1,num_layers+1):\n",
    "\n",
    "    module = str(m[layer][-2])\n",
    "    match = re.search(r'out_channels=(\\d+)R', module)\n",
    "    out_channels = int(match.group(1))\n",
    "    num_params += out_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4da4b8-ca31-4a74-8dcc-d8358a5d8d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ToSplitTensor()\n",
       "  (1): Sequential(\n",
       "    (0): Scattering2D(input_channels=3R, S=1, L=8, spatial=(224,224) to (112,112), phi_channels=3R, psi_channels=24C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(27,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=27R, out_channels=32R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Scattering2D(input_channels=32R, S=1, L=8, spatial=(112,112) to (112,112), phi_channels=32R, psi_channels=256C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(288,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=288R, out_channels=64R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Scattering2D(input_channels=64R, S=1, L=8, spatial=(112,112) to (56,56), phi_channels=64R, psi_channels=512C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(576,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=576R, out_channels=64R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Scattering2D(input_channels=64R, S=1, L=8, spatial=(56,56) to (56,56), phi_channels=64R, psi_channels=512C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(576,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=576R, out_channels=128R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Scattering2D(input_channels=128R, S=1, L=8, spatial=(56,56) to (28,28), phi_channels=128R, psi_channels=1024C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(1152,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=1152R, out_channels=256R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Scattering2D(input_channels=256R, S=1, L=8, spatial=(28,28) to (28,28), phi_channels=256R, psi_channels=2048C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(2304,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=2304R, out_channels=512R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(28,28) to (14,14), phi_channels=512R, psi_channels=4096C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=4608R, out_channels=512R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (8): Sequential(\n",
       "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(14,14) to (14,14), phi_channels=512R, psi_channels=4096C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=4608R, out_channels=512R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (9): Sequential(\n",
       "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(14,14) to (7,7), phi_channels=512R, psi_channels=4096C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=4608R, out_channels=512R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (10): Sequential(\n",
       "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(7,7) to (6,6), phi_channels=512R, psi_channels=4096C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=4608R, out_channels=512R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (11): Sequential(\n",
       "    (0): Scattering2D(input_channels=512R, S=1, L=8, spatial=(6,6) to (3,3), phi_channels=512R, psi_channels=4096C)\n",
       "    (1): Branching(\n",
       "      (psi): ScatNonLinearity(non_linearity=mod, complex=C2R)\n",
       "    )\n",
       "    (2): BatchedModule(Standardization(dim=(1,), shape=(4608,), complex=False, remove_mean=True))\n",
       "    (3): DiagonalModule(ModuleDict(\n",
       "      (0): ComplexConv2d(in_channels=4608R, out_channels=256R, complex_weights=False)\n",
       "    ))\n",
       "    (4): DiagonalModule(ModuleDict(\n",
       "      (0): Normalization(dim=1, p=2)\n",
       "    ))\n",
       "  )\n",
       "  (12): ToTensor()\n",
       "  (13): Classifier(\n",
       "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (classifier): Linear(in_features=2304, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ddcf8f7b-0984-451d-98db-27c5e148cccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3360"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8146a765-ed4a-434b-ac13-3c50d6f1934d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11907])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2204973-e90c-4f3d-9a66-73049695f5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e25f0e-1e35-42c2-826d-fc24c64ba82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dacb5fad-44d8-498a-a547-04e7b20b2d5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Convolution w/o weight sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211180e8-da62-48fa-a40c-9488997b44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NonSharedConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        super(NonSharedConv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        # Calculate the expected size of the weights\n",
    "        self.weight_shape = (out_channels, in_channels, kernel_size, kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the input dimensions\n",
    "        batch_size, _, height, width = x.shape\n",
    "\n",
    "        # Calculate output dimensions\n",
    "        out_height = (height + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "        out_width = (width + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
    "\n",
    "        # Initialize random weights for each patch\n",
    "        weights = torch.randn(batch_size, out_height, out_width, *self.weight_shape, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        # Initialize output tensor\n",
    "        output = torch.zeros(batch_size, self.out_channels, out_height, out_width, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        # Apply convolution without weight sharing\n",
    "        for i in range(out_height):\n",
    "            for j in range(out_width):\n",
    "                h_start = i * self.stride\n",
    "                h_end = h_start + self.kernel_size\n",
    "                w_start = j * self.stride\n",
    "                w_end = w_start + self.kernel_size\n",
    "\n",
    "                # Extract the patch\n",
    "                patch = x[:, :, h_start:h_end, w_start:w_end]\n",
    "\n",
    "                # Apply the convolution operation\n",
    "                for b in range(batch_size):\n",
    "                    for c in range(self.out_channels):\n",
    "                        output[b, c, i, j] = torch.sum(patch[b, :, :, :] * weights[b, i, j, c, :, :, :])\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf39d88-4576-4885-b518-9e0377001b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = NonSharedConv2d(in_channels=108, out_channels=1000, kernel_size, stride=1, padding=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
