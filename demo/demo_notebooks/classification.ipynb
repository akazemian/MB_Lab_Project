{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atlask/Desktop/untrained_models_of_visual_cortex/code/model_activations/activation_extractor.py:21: UserWarning: my warning\n",
      "  warnings.warn('my warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "from config import CACHE, RESULTS_PATH, setup_logging\n",
    "from demo.model_configs import analysis_cfg as cfg\n",
    "from code.model_activations.models.utils import load_model, load_full_identifier\n",
    "from code.model_activations.activation_extractor import Activations\n",
    "from code.image_classification.classification_tools import get_Xy, cv_performance\n",
    "from code.eigen_analysis.compute_pcs import compute_model_pcs\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAMES = ['expansion','alexnet']\n",
    "PCA_DATASET = 'places_train_demo'\n",
    "DATASET = 'places_val_demo'\n",
    "NUM_COMPONENTS = 100\n",
    "DEVICE = 'cuda'\n",
    "BATCH_SIZE = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting classification results for: expansion_features=3_layers=5_dataset=places_val_demo_principal_components=100\n",
      "Computing model principal components using a subset of the Places train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 14:55:20,806 - INFO - Loading processed images...\n",
      "2024-06-27 14:55:20,994 - INFO - Extracting activations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting activations from the Places val set and projecting them onto the learned PCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:26<00:00,  2.60s/it]\n",
      "2024-06-27 14:55:47,128 - INFO - Model activations are saved in cache\n",
      "2024-06-27 14:55:47,214 - INFO - Extracting activations from the Places val set and projecting them onto the learned PCs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting classification results for: alexnet_conv5_layers=5_features=256_dataset=places_val_demo_principal_components=100\n",
      "Computing model principal components using a subset of the Places train set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atlask/anaconda3/envs/final_test/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/atlask/anaconda3/envs/final_test/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "2024-06-27 14:55:54,731 - INFO - Loading processed images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting activations from the Places val set and projecting them onto the learned PCs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 14:55:54,929 - INFO - Extracting activations...\n",
      "100%|██████████| 10/10 [00:00<00:00, 59.59it/s]\n",
      "2024-06-27 14:55:55,101 - INFO - Model activations are saved in cache\n",
      "2024-06-27 14:55:55,182 - INFO - Extracting activations from the Places val set and projecting them onto the learned PCs\n"
     ]
    }
   ],
   "source": [
    "for model_name in MODEL_NAMES:\n",
    "    # get model activation iden\n",
    "    activations_identifier = load_full_identifier(model_name=model_name, \n",
    "                                            features=cfg[DATASET]['models'][model_name]['features'], \n",
    "                                            layers=cfg[DATASET]['models'][model_name]['layers'], \n",
    "                                            dataset=DATASET,\n",
    "                                            principal_components = NUM_COMPONENTS)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(RESULTS_PATH,f'classification_{model_name}')):\n",
    "        print(f\"Getting classification results for: {activations_identifier}\")\n",
    "        \n",
    "        \n",
    "        pca_identifier = load_full_identifier(model_name=model_name, \n",
    "                                                    features=cfg[PCA_DATASET]['models'][model_name]['features'], \n",
    "                                                    layers=cfg[PCA_DATASET]['models'][model_name]['layers'], \n",
    "                                                    dataset=PCA_DATASET,\n",
    "                                                    principal_components = NUM_COMPONENTS)\n",
    "        \n",
    "        print(f\"Computing model principal components using a subset of the Places train set\")\n",
    "        if not os.path.exists(os.path.join(CACHE,'pca',pca_identifier)):\n",
    "            compute_model_pcs(model_name = model_name, \n",
    "                            features=cfg[PCA_DATASET]['models'][model_name]['features'],  \n",
    "                            layers=cfg[PCA_DATASET]['models'][model_name]['layers'], \n",
    "                            dataset = PCA_DATASET, \n",
    "                            components = NUM_COMPONENTS, \n",
    "                            device = DEVICE,\n",
    "                            batch_size=BATCH_SIZE)\n",
    "            \n",
    "        # load model\n",
    "        model = load_model(model_name=model_name, \n",
    "                        features=cfg[DATASET]['models'][model_name]['features'], \n",
    "                        layers=cfg[DATASET]['models'][model_name]['layers'],\n",
    "                        device=DEVICE)\n",
    "        \n",
    "        print(f\"Extracting activations from the Places val set and projecting them onto the learned PCs\")\n",
    "        # compute activations and project onto PCs\n",
    "        Activations(model=model, \n",
    "                    dataset=DATASET, \n",
    "                    pca_iden = pca_identifier,\n",
    "                    n_components = NUM_COMPONENTS, \n",
    "                    batch_size = BATCH_SIZE,\n",
    "                    device= DEVICE).get_array(activations_identifier)  \n",
    "        \n",
    "        logging.info(f\"Extracting activations from the Places val set and projecting them onto the learned PCs\")\n",
    "        X, y = get_Xy(data=xr.open_dataset(os.path.join(CACHE,'activations',activations_identifier), \n",
    "                            engine='netcdf4').set_xindex('stimulus_id'))\n",
    "        score = cv_performance(X, y, class_balance=False)\n",
    "\n",
    "        with open(os.path.join(RESULTS_PATH,f'classification_{model_name}'),'wb') as f:\n",
    "            pickle.dump(score,f)\n",
    "    else:\n",
    "        print(f'results for model: {activations_identifier} are already saved in cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expansion : 0.002\n",
      "alexnet : 0.048\n"
     ]
    }
   ],
   "source": [
    "# load expansion results\n",
    "for model_name in MODEL_NAMES:\n",
    "\n",
    "    with open(os.path.join(RESULTS_PATH, f'classification_{model_name}'),'rb') as f:\n",
    "        accuracy_score = pickle.load(f)\n",
    "    print(model_name, ':', accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
